{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/CoordConv-pytorch/experiments/paste\n",
      "Namespace(b1=0.5, b2=0.999, batch_size=1, channels=1, clip_value=0.01, img_size=8, latent_dim=100, lr=0.0002, n_cpu=8, n_critic=50, n_epochs=10000, sample_interval=400)\n",
      "0 7 4.527130126953125\n",
      "100 7 1.0302684307098389\n",
      "200 7 0.4067881107330322\n",
      "300 7 1.9823647737503052\n",
      "400 7 0.3324251174926758\n",
      "500 7 0.6767411828041077\n",
      "600 7 0.2608996629714966\n",
      "700 7 0.32876938581466675\n",
      "800 7 0.2206534892320633\n",
      "900 7 0.01647399552166462\n",
      "1000 7 0.11994506418704987\n",
      "1100 7 0.004937151446938515\n",
      "1200 7 0.0018520228331908584\n",
      "1300 7 0.006954972166568041\n",
      "1400 7 0.0021792107727378607\n",
      "1500 7 3.6040775739820674e-05\n",
      "1600 7 1.3445244917420496e-07\n",
      "1700 7 1.2533973858808167e-09\n",
      "1800 7 3.952393967665557e-12\n",
      "1900 7 7.105427357601002e-13\n",
      "2000 7 3.481659405224491e-13\n",
      "2100 7 0.0\n",
      "2200 7 4.440892098500626e-14\n",
      "2300 7 2.842170943040401e-14\n",
      "2400 7 0.0\n",
      "2500 7 0.0\n",
      "2600 7 0.0\n",
      "2700 7 0.0\n",
      "2800 7 0.0\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"train_simple.py\", line 176, in <module>\n",
      "    train()\n",
      "  File \"train_simple.py\", line 157, in train\n",
      "    y = net(x)\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 493, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"train_simple.py\", line 107, in forward\n",
      "    return self.model(x)\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 493, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/torch/nn/modules/container.py\", line 92, in forward\n",
      "    input = module(input)\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 493, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/torch/nn/modules/linear.py\", line 92, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/torch/nn/functional.py\", line 1406, in linear\n",
      "    ret = torch.addmm(bias, input, weight.t())\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "%cd /notebooks/CoordConv-pytorch/experiments/paste/\n",
    "!python train_simple.py --img_size=8 --batch_size=1 --n_epochs=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/CoordConv-pytorch/experiments/gan/munit\n",
      "Namespace(b1=0.5, b2=0.999, batch_size=64, channels=1, clip_value=0.01, data_path='data/layout', img_size=64, latent_dim=4, lr=0.0002, model_path='saved_models/95000.pt', n_cpu=8, n_critic=1, n_epochs=100000, sample_interval=100)\n",
      "[Epoch 0/100000] [Batch 0/1] [D loss: 7.959727] [G loss: 10.037612]\n",
      "[Epoch 100/100000] [Batch 0/1] [D loss: -20.445877] [G loss: 1.710520]\n",
      "[Epoch 200/100000] [Batch 0/1] [D loss: -2.766628] [G loss: 3.130843]\n",
      "[Epoch 300/100000] [Batch 0/1] [D loss: -1.626384] [G loss: -3.134868]\n",
      "[Epoch 400/100000] [Batch 0/1] [D loss: -3.010446] [G loss: -2.922170]\n",
      "[Epoch 500/100000] [Batch 0/1] [D loss: -0.434553] [G loss: 1.187312]\n",
      "[Epoch 600/100000] [Batch 0/1] [D loss: -1.060011] [G loss: 1.198974]\n",
      "[Epoch 700/100000] [Batch 0/1] [D loss: 0.118041] [G loss: 6.224486]\n",
      "[Epoch 800/100000] [Batch 0/1] [D loss: -0.669772] [G loss: 1.493773]\n",
      "[Epoch 900/100000] [Batch 0/1] [D loss: 0.103961] [G loss: -5.356470]\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"train_layout.py\", line 292, in <module>\n",
      "    train_wgan()\n",
      "  File \"train_layout.py\", line 256, in train_wgan\n",
      "    d_loss.backward()\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/torch/tensor.py\", line 107, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/torch/autograd/__init__.py\", line 93, in backward\n",
      "    allow_unreachable=True)  # allow_unreachable flag\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "%cd /notebooks/CoordConv-pytorch/experiments/gan/munit\n",
    "!rm -R data\n",
    "!rm -R images\n",
    "# !rm -R saved_models\n",
    "!python train_layout.py --n_epochs=100000 --latent_dim=4 --channels=1 --img_size=64 --n_critic=1 --sample_interval=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "18//4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
