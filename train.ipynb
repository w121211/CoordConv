{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Docker\n",
    "\n",
    "```bash\n",
    "sudo docker run --runtime=nvidia -d -it --rm -p=8888:8888 --ipc=\"host\" -v=/home/chi/Documents:/tf tensorflow/tensorflow:2.0.0rc0-gpu-py3-jupyter\n",
    "sudo docker logs ...\n",
    "sudo docker start ...\n",
    "sudo docker exec -it ... /bin/bash\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/CoordConv-pytorch/gan-textbox\n",
      "Namespace(b1=0.5, b2=0.999, batch_size=64, channels=1, clip_value=0.01, data_path='data/layout', img_size=64, latent_dim=10, lr=0.0002, model_path='saved_models/95000.pt', n_cpu=8, n_critic=50, n_epochs=200, sample_interval=400)\n",
      "Traceback (most recent call last):\n",
      "  File \"train_toy_pasteline.py\", line 372, in <module>\n",
      "    train_g_supervised()\n",
      "  File \"train_toy_pasteline.py\", line 239, in train_g_supervised\n",
      "    fake_imgs, coords = generator(text_status, chars, char_sizes)\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 493, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "TypeError: forward() missing 1 required positional argument: 'char_sizes'\n"
     ]
    }
   ],
   "source": [
    "%cd /notebooks/CoordConv-pytorch/gan-textbox\n",
    "!python train_toy_pasteline.py --img_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create font image dataset\n",
    "# %cd /notebooks/CoordConv-pytorch/font2img\n",
    "# !python font2img.py \\\n",
    "#     /notebooks/post-generator/asset/fonts_en/Alegreya \\\n",
    "#     /notebooks/CoordConv-pytorch/font2img/src_chars_txt/alphabets_hankaku_caps.txt \\\n",
    "#     /notebooks/CoordConv-pytorch/data/fontimg\n",
    "#     --by-char\n",
    "\n",
    "# train Char-GAN\n",
    "# %cd /notebooks/CoordConv-pytorch/gan-char\n",
    "# !python train.py --sample_interval 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/CoordConv-pytorch/gan-textbox\n",
      "Namespace(b1=0.5, b2=0.999, batch_size=1, channels=3, checkpoint_interval=-1, dataset_name='edges2shoes', decay_epoch=100, dim=64, epoch=0, img_height=128, img_width=128, lr=0.0001, n_cpu=8, n_downsample=2, n_epochs=200, n_residual=3, sample_interval=400, style_dim=8)\n",
      "[Epoch 0/200] [Batch 4/234] [D loss: 6.972351] [G loss: 15.614893] ETA: 7 days, 6:19:33.33554340^C\n",
      "Traceback (most recent call last):\n",
      "  File \"train_char_transfer_gan.py\", line 353, in <module>\n",
      "    optimizer_G.step()\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/torch/optim/adam.py\", line 101, in step\n",
      "    denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "%cd /notebooks/CoordConv-pytorch/gan-textbox\n",
    "!python train_char_transfer_gan.py \n",
    "# !rm -R data/regressor\n",
    "# !python -m experiments.regressor.train_shape --img_size=64 --n_epochs=100 --n_strokes=4 --sample_interval=10 --n_samples=10\n",
    "# !python train_toy_pasteline.py --batch_size=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/CoordConv-pytorch/experiments/gan/munit\n",
      "Namespace(b1=0.5, b2=0.999, batch_size=64, channels=1, clip_value=0.01, data_path='data/layout', img_size=64, latent_dim=4, lr=0.0002, model_path='saved_models/95000.pt', n_cpu=8, n_critic=1, n_epochs=100000, sample_interval=100)\n",
      "[Epoch 0/100000] [Batch 0/2] [D loss: 8.145257] [G loss: 7.907234]\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"train_layout_by_params.py\", line 351, in <module>\n",
      "    train_wgan()\n",
      "  File \"train_layout_by_params.py\", line 307, in train_wgan\n",
      "    discriminator, real_imgs.data, fake_imgs.data\n",
      "  File \"/notebooks/CoordConv-pytorch/experiments/gan/munit/models.py\", line 467, in compute_gradient_penalty\n",
      "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/torch/tensor.py\", line 253, in norm\n",
      "    return torch.norm(self, p, dim, keepdim, dtype=dtype)\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/torch/functional.py\", line 705, in norm\n",
      "    return torch._C._VariableFunctions.norm(input, p, dim, keepdim=keepdim)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "%cd /notebooks/CoordConv-pytorch/experiments/gan/munit\n",
    "!rm -R data\n",
    "!rm -R images\n",
    "# !rm -R saved_models\n",
    "!python train_layout_by_params.py --n_epochs=100000 --latent_dim=4 --channels=1 --img_size=64 --n_critic=1 --sample_interval=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "18//4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
