{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/CoordConv-pytorch/experiments/paste\n",
      "Namespace(b1=0.5, b2=0.999, batch_size=1, channels=1, clip_value=0.01, img_size=8, latent_dim=100, lr=0.0002, n_cpu=8, n_critic=50, n_epochs=10000, sample_interval=400)\n",
      "0 7 4.527130126953125\n",
      "100 7 1.0302684307098389\n",
      "200 7 0.4067881107330322\n",
      "300 7 1.9823647737503052\n",
      "400 7 0.3324251174926758\n",
      "500 7 0.6767411828041077\n",
      "600 7 0.2608996629714966\n",
      "700 7 0.32876938581466675\n",
      "800 7 0.2206534892320633\n",
      "900 7 0.01647399552166462\n",
      "1000 7 0.11994506418704987\n",
      "1100 7 0.004937151446938515\n",
      "1200 7 0.0018520228331908584\n",
      "1300 7 0.006954972166568041\n",
      "1400 7 0.0021792107727378607\n",
      "1500 7 3.6040775739820674e-05\n",
      "1600 7 1.3445244917420496e-07\n",
      "1700 7 1.2533973858808167e-09\n",
      "1800 7 3.952393967665557e-12\n",
      "1900 7 7.105427357601002e-13\n",
      "2000 7 3.481659405224491e-13\n",
      "2100 7 0.0\n",
      "2200 7 4.440892098500626e-14\n",
      "2300 7 2.842170943040401e-14\n",
      "2400 7 0.0\n",
      "2500 7 0.0\n",
      "2600 7 0.0\n",
      "2700 7 0.0\n",
      "2800 7 0.0\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"train_simple.py\", line 176, in <module>\n",
      "    train()\n",
      "  File \"train_simple.py\", line 157, in train\n",
      "    y = net(x)\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 493, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"train_simple.py\", line 107, in forward\n",
      "    return self.model(x)\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 493, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/torch/nn/modules/container.py\", line 92, in forward\n",
      "    input = module(input)\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 493, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/torch/nn/modules/linear.py\", line 92, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/torch/nn/functional.py\", line 1406, in linear\n",
      "    ret = torch.addmm(bias, input, weight.t())\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "%cd /notebooks/CoordConv-pytorch/experiments/paste/\n",
    "!python train_simple.py --img_size=8 --batch_size=1 --n_epochs=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/CoordConv-pytorch/experiments/gan/munit\n",
      "Namespace(b1=0.5, b2=0.999, batch_size=64, channels=1, clip_value=0.01, img_size=64, latent_dim=4, lr=0.0002, n_cpu=8, n_critic=50, n_epochs=100000, sample_interval=400)\n",
      "[Epoch 0/100000] [Batch 0/2] [D loss: 8.056545] [G loss: 1.024733]\n",
      "[Epoch 1/100000] [Batch 0/2] [D loss: 3.890053] [G loss: 1.005123]\n",
      "[Epoch 2/100000] [Batch 0/2] [D loss: -3.248317] [G loss: 0.964883]\n",
      "[Epoch 3/100000] [Batch 0/2] [D loss: -13.861038] [G loss: 0.835345]\n",
      "[Epoch 4/100000] [Batch 0/2] [D loss: -27.859011] [G loss: 0.468401]\n",
      "[Epoch 5/100000] [Batch 0/2] [D loss: -44.382145] [G loss: -0.347269]\n",
      "[Epoch 6/100000] [Batch 0/2] [D loss: -61.464058] [G loss: -1.977134]\n",
      "[Epoch 7/100000] [Batch 0/2] [D loss: -76.358841] [G loss: -4.963981]\n",
      "[Epoch 8/100000] [Batch 0/2] [D loss: -85.862068] [G loss: -9.871859]\n",
      "[Epoch 9/100000] [Batch 0/2] [D loss: -88.164436] [G loss: -17.437071]\n",
      "[Epoch 10/100000] [Batch 0/2] [D loss: -81.951324] [G loss: -27.864456]\n",
      "[Epoch 11/100000] [Batch 0/2] [D loss: -69.963959] [G loss: -40.456169]\n",
      "[Epoch 12/100000] [Batch 0/2] [D loss: -53.907734] [G loss: -53.813747]\n",
      "[Epoch 13/100000] [Batch 0/2] [D loss: -35.500702] [G loss: -66.985664]\n",
      "[Epoch 14/100000] [Batch 0/2] [D loss: -18.825460] [G loss: -75.910233]\n",
      "[Epoch 15/100000] [Batch 0/2] [D loss: -4.328218] [G loss: -80.050186]\n",
      "[Epoch 16/100000] [Batch 0/2] [D loss: 3.684686] [G loss: -77.207123]\n",
      "[Epoch 17/100000] [Batch 0/2] [D loss: 5.992581] [G loss: -69.495758]\n",
      "[Epoch 18/100000] [Batch 0/2] [D loss: 6.344540] [G loss: -61.163406]\n",
      "[Epoch 19/100000] [Batch 0/2] [D loss: 5.186607] [G loss: -52.928658]\n",
      "[Epoch 20/100000] [Batch 0/2] [D loss: 2.920417] [G loss: -45.530781]\n",
      "[Epoch 21/100000] [Batch 0/2] [D loss: 0.822644] [G loss: -38.798019]\n",
      "[Epoch 22/100000] [Batch 0/2] [D loss: 0.004798] [G loss: -32.488384]\n",
      "[Epoch 23/100000] [Batch 0/2] [D loss: -0.551786] [G loss: -26.275557]\n",
      "[Epoch 24/100000] [Batch 0/2] [D loss: -3.765953] [G loss: -19.781681]\n",
      "[Epoch 25/100000] [Batch 0/2] [D loss: -5.193654] [G loss: -11.746555]\n",
      "[Epoch 26/100000] [Batch 0/2] [D loss: -9.716452] [G loss: -1.481266]\n",
      "[Epoch 27/100000] [Batch 0/2] [D loss: -10.765634] [G loss: 9.289701]\n",
      "[Epoch 28/100000] [Batch 0/2] [D loss: -12.649239] [G loss: 15.545506]\n",
      "[Epoch 29/100000] [Batch 0/2] [D loss: -13.005075] [G loss: 20.158701]\n",
      "[Epoch 30/100000] [Batch 0/2] [D loss: -12.533422] [G loss: 24.343912]\n",
      "[Epoch 31/100000] [Batch 0/2] [D loss: -13.806181] [G loss: 28.464741]\n",
      "[Epoch 32/100000] [Batch 0/2] [D loss: -11.484795] [G loss: 33.531128]\n",
      "[Epoch 33/100000] [Batch 0/2] [D loss: -10.609095] [G loss: 38.333885]\n",
      "[Epoch 34/100000] [Batch 0/2] [D loss: -10.829669] [G loss: 41.949009]\n",
      "[Epoch 35/100000] [Batch 0/2] [D loss: -8.983691] [G loss: 47.352184]\n",
      "[Epoch 36/100000] [Batch 0/2] [D loss: -8.205768] [G loss: 47.853523]\n",
      "[Epoch 37/100000] [Batch 0/2] [D loss: -5.734410] [G loss: 49.792389]\n",
      "[Epoch 38/100000] [Batch 0/2] [D loss: -5.029251] [G loss: 51.165257]\n",
      "[Epoch 39/100000] [Batch 0/2] [D loss: -3.942782] [G loss: 49.850010]\n",
      "[Epoch 40/100000] [Batch 0/2] [D loss: -1.795804] [G loss: 44.851654]\n",
      "[Epoch 41/100000] [Batch 0/2] [D loss: -0.338579] [G loss: 38.912514]\n",
      "[Epoch 42/100000] [Batch 0/2] [D loss: -0.911567] [G loss: 30.957764]\n",
      "[Epoch 43/100000] [Batch 0/2] [D loss: -0.271334] [G loss: 21.298592]\n",
      "[Epoch 44/100000] [Batch 0/2] [D loss: -4.178359] [G loss: 14.045113]\n",
      "[Epoch 45/100000] [Batch 0/2] [D loss: -2.804580] [G loss: 9.125340]\n",
      "[Epoch 46/100000] [Batch 0/2] [D loss: -2.874298] [G loss: 7.869256]\n",
      "[Epoch 47/100000] [Batch 0/2] [D loss: -0.609112] [G loss: 3.553076]\n",
      "[Epoch 48/100000] [Batch 0/2] [D loss: -1.374522] [G loss: 2.459626]\n",
      "[Epoch 49/100000] [Batch 0/2] [D loss: -1.379161] [G loss: -2.149992]\n",
      "[Epoch 50/100000] [Batch 0/2] [D loss: -3.523668] [G loss: -7.699050]\n",
      "[Epoch 51/100000] [Batch 0/2] [D loss: -9.047248] [G loss: -14.491991]\n",
      "[Epoch 52/100000] [Batch 0/2] [D loss: -15.596622] [G loss: -24.817348]\n",
      "[Epoch 53/100000] [Batch 0/2] [D loss: -20.431833] [G loss: -37.810612]\n",
      "[Epoch 54/100000] [Batch 0/2] [D loss: -17.822315] [G loss: -52.064732]\n",
      "[Epoch 55/100000] [Batch 0/2] [D loss: -9.764453] [G loss: -62.186871]\n",
      "[Epoch 56/100000] [Batch 0/2] [D loss: -0.952584] [G loss: -64.821541]\n",
      "[Epoch 57/100000] [Batch 0/2] [D loss: 4.233194] [G loss: -61.584087]\n",
      "[Epoch 58/100000] [Batch 0/2] [D loss: 5.670058] [G loss: -54.627136]\n",
      "[Epoch 59/100000] [Batch 0/2] [D loss: 5.215514] [G loss: -48.238232]\n",
      "[Epoch 60/100000] [Batch 0/2] [D loss: 3.329633] [G loss: -40.964520]\n",
      "[Epoch 61/100000] [Batch 0/2] [D loss: 1.576573] [G loss: -34.902946]\n",
      "[Epoch 62/100000] [Batch 0/2] [D loss: -0.592080] [G loss: -29.878555]\n",
      "[Epoch 63/100000] [Batch 0/2] [D loss: -2.872907] [G loss: -25.070709]\n",
      "[Epoch 64/100000] [Batch 0/2] [D loss: -3.412947] [G loss: -21.343914]\n",
      "[Epoch 65/100000] [Batch 0/2] [D loss: -4.927727] [G loss: -18.247641]\n",
      "[Epoch 66/100000] [Batch 0/2] [D loss: -6.537383] [G loss: -16.561893]\n",
      "[Epoch 67/100000] [Batch 0/2] [D loss: -6.303150] [G loss: -15.036176]\n",
      "[Epoch 68/100000] [Batch 0/2] [D loss: -6.097678] [G loss: -11.243081]\n",
      "[Epoch 69/100000] [Batch 0/2] [D loss: -6.850219] [G loss: -10.287397]\n",
      "[Epoch 70/100000] [Batch 0/2] [D loss: -6.160313] [G loss: -9.800848]\n",
      "[Epoch 71/100000] [Batch 0/2] [D loss: -5.662809] [G loss: -6.563767]\n",
      "[Epoch 72/100000] [Batch 0/2] [D loss: -5.680620] [G loss: -7.088499]\n",
      "[Epoch 73/100000] [Batch 0/2] [D loss: -4.175104] [G loss: -5.014036]\n",
      "[Epoch 74/100000] [Batch 0/2] [D loss: -5.581052] [G loss: -4.943430]\n",
      "[Epoch 75/100000] [Batch 0/2] [D loss: -4.172144] [G loss: -4.398456]\n",
      "[Epoch 76/100000] [Batch 0/2] [D loss: -4.099161] [G loss: -3.667470]\n",
      "[Epoch 77/100000] [Batch 0/2] [D loss: -3.288411] [G loss: -3.770344]\n",
      "[Epoch 78/100000] [Batch 0/2] [D loss: -3.454743] [G loss: -3.143543]\n",
      "[Epoch 79/100000] [Batch 0/2] [D loss: -1.624463] [G loss: -3.415221]\n",
      "[Epoch 80/100000] [Batch 0/2] [D loss: -2.893466] [G loss: -3.151314]\n",
      "[Epoch 81/100000] [Batch 0/2] [D loss: -1.702737] [G loss: -3.483206]\n",
      "[Epoch 82/100000] [Batch 0/2] [D loss: -1.725494] [G loss: -3.587824]\n",
      "[Epoch 83/100000] [Batch 0/2] [D loss: -1.936590] [G loss: -4.051883]\n",
      "[Epoch 84/100000] [Batch 0/2] [D loss: -1.412391] [G loss: -4.449499]\n",
      "[Epoch 85/100000] [Batch 0/2] [D loss: -2.117461] [G loss: -5.313646]\n",
      "[Epoch 86/100000] [Batch 0/2] [D loss: -1.585306] [G loss: -5.491880]\n",
      "[Epoch 87/100000] [Batch 0/2] [D loss: -2.418036] [G loss: -6.646295]\n",
      "[Epoch 88/100000] [Batch 0/2] [D loss: -1.560492] [G loss: -6.862441]\n",
      "[Epoch 89/100000] [Batch 0/2] [D loss: -2.808093] [G loss: -7.768633]\n",
      "[Epoch 90/100000] [Batch 0/2] [D loss: -3.011716] [G loss: -8.367683]\n",
      "[Epoch 91/100000] [Batch 0/2] [D loss: -2.662132] [G loss: -9.017382]\n",
      "[Epoch 92/100000] [Batch 0/2] [D loss: -2.996397] [G loss: -9.215046]\n",
      "[Epoch 93/100000] [Batch 0/2] [D loss: -3.649975] [G loss: -9.721225]\n",
      "[Epoch 94/100000] [Batch 0/2] [D loss: -3.403432] [G loss: -9.681909]\n",
      "[Epoch 95/100000] [Batch 0/2] [D loss: -4.248005] [G loss: -9.919127]\n",
      "[Epoch 96/100000] [Batch 0/2] [D loss: -4.789588] [G loss: -10.276127]\n",
      "[Epoch 97/100000] [Batch 0/2] [D loss: -6.154369] [G loss: -10.303484]\n",
      "[Epoch 98/100000] [Batch 0/2] [D loss: -7.335873] [G loss: -9.970766]\n",
      "[Epoch 99/100000] [Batch 0/2] [D loss: -7.851681] [G loss: -10.493713]\n",
      "[Epoch 100/100000] [Batch 0/2] [D loss: -7.761521] [G loss: -10.504290]\n",
      "[Epoch 101/100000] [Batch 0/2] [D loss: -10.411224] [G loss: -10.675549]\n",
      "[Epoch 102/100000] [Batch 0/2] [D loss: -11.744137] [G loss: -10.720407]\n",
      "[Epoch 103/100000] [Batch 0/2] [D loss: -13.183244] [G loss: -10.634093]\n",
      "[Epoch 104/100000] [Batch 0/2] [D loss: -14.647877] [G loss: -10.787131]\n",
      "[Epoch 105/100000] [Batch 0/2] [D loss: -17.033028] [G loss: -9.602169]\n",
      "[Epoch 106/100000] [Batch 0/2] [D loss: -18.877415] [G loss: -9.832413]\n",
      "[Epoch 107/100000] [Batch 0/2] [D loss: -19.642855] [G loss: -8.524930]\n",
      "[Epoch 108/100000] [Batch 0/2] [D loss: -22.406269] [G loss: -7.654001]\n",
      "[Epoch 109/100000] [Batch 0/2] [D loss: -24.234217] [G loss: -7.666673]\n",
      "[Epoch 110/100000] [Batch 0/2] [D loss: -25.246069] [G loss: -4.180987]\n",
      "[Epoch 111/100000] [Batch 0/2] [D loss: -25.942818] [G loss: -3.547959]\n",
      "[Epoch 112/100000] [Batch 0/2] [D loss: -26.310305] [G loss: -3.961538]\n",
      "[Epoch 113/100000] [Batch 0/2] [D loss: -27.841719] [G loss: 2.090091]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 114/100000] [Batch 0/2] [D loss: -29.009054] [G loss: 6.957072]\n",
      "[Epoch 115/100000] [Batch 0/2] [D loss: -30.938065] [G loss: 15.928317]\n",
      "[Epoch 116/100000] [Batch 0/2] [D loss: -32.285706] [G loss: 28.236729]\n",
      "[Epoch 117/100000] [Batch 0/2] [D loss: -33.581013] [G loss: 31.600691]\n",
      "[Epoch 118/100000] [Batch 0/2] [D loss: -35.008827] [G loss: 34.174343]\n",
      "[Epoch 119/100000] [Batch 0/2] [D loss: -34.231602] [G loss: 30.507366]\n",
      "[Epoch 120/100000] [Batch 0/2] [D loss: -34.681168] [G loss: 29.801313]\n",
      "[Epoch 121/100000] [Batch 0/2] [D loss: -34.726860] [G loss: 24.841530]\n",
      "[Epoch 122/100000] [Batch 0/2] [D loss: -33.656998] [G loss: 21.516623]\n",
      "[Epoch 123/100000] [Batch 0/2] [D loss: -32.908089] [G loss: 19.635334]\n",
      "[Epoch 124/100000] [Batch 0/2] [D loss: -34.150757] [G loss: 16.799271]\n",
      "[Epoch 125/100000] [Batch 0/2] [D loss: -33.820038] [G loss: 13.983248]\n",
      "[Epoch 126/100000] [Batch 0/2] [D loss: -33.732018] [G loss: 11.656063]\n",
      "[Epoch 127/100000] [Batch 0/2] [D loss: -34.705345] [G loss: 7.879390]\n",
      "[Epoch 128/100000] [Batch 0/2] [D loss: -35.571362] [G loss: 6.164586]\n",
      "[Epoch 129/100000] [Batch 0/2] [D loss: -34.639130] [G loss: 0.980251]\n",
      "[Epoch 130/100000] [Batch 0/2] [D loss: -37.555702] [G loss: -0.312930]\n",
      "[Epoch 131/100000] [Batch 0/2] [D loss: -38.690735] [G loss: -5.448570]\n",
      "[Epoch 132/100000] [Batch 0/2] [D loss: -38.394379] [G loss: -6.058907]\n",
      "[Epoch 133/100000] [Batch 0/2] [D loss: -38.747055] [G loss: -8.910416]\n",
      "[Epoch 134/100000] [Batch 0/2] [D loss: -38.089355] [G loss: -11.401937]\n",
      "[Epoch 135/100000] [Batch 0/2] [D loss: -39.671913] [G loss: -11.681125]\n",
      "[Epoch 136/100000] [Batch 0/2] [D loss: -37.685181] [G loss: -11.654129]\n",
      "[Epoch 137/100000] [Batch 0/2] [D loss: -38.573940] [G loss: -9.083155]\n",
      "[Epoch 138/100000] [Batch 0/2] [D loss: -37.714615] [G loss: -6.047456]\n",
      "[Epoch 139/100000] [Batch 0/2] [D loss: -39.861458] [G loss: -3.966938]\n",
      "[Epoch 140/100000] [Batch 0/2] [D loss: -40.046234] [G loss: 1.168977]\n",
      "[Epoch 141/100000] [Batch 0/2] [D loss: -39.697990] [G loss: 3.981918]\n",
      "[Epoch 142/100000] [Batch 0/2] [D loss: -40.210579] [G loss: 4.860388]\n",
      "[Epoch 143/100000] [Batch 0/2] [D loss: -39.999168] [G loss: 6.642983]\n",
      "[Epoch 144/100000] [Batch 0/2] [D loss: -40.879974] [G loss: 7.214624]\n",
      "[Epoch 145/100000] [Batch 0/2] [D loss: -40.148277] [G loss: 5.845945]\n",
      "[Epoch 146/100000] [Batch 0/2] [D loss: -41.259388] [G loss: 4.750832]\n",
      "[Epoch 147/100000] [Batch 0/2] [D loss: -42.504456] [G loss: 2.542134]\n",
      "[Epoch 148/100000] [Batch 0/2] [D loss: -40.029549] [G loss: 2.175997]\n",
      "[Epoch 149/100000] [Batch 0/2] [D loss: -42.881538] [G loss: -0.800532]\n",
      "[Epoch 150/100000] [Batch 0/2] [D loss: -42.395554] [G loss: 0.302901]\n",
      "[Epoch 151/100000] [Batch 0/2] [D loss: -43.089741] [G loss: 0.150507]\n",
      "[Epoch 152/100000] [Batch 0/2] [D loss: -43.789558] [G loss: 0.708250]\n",
      "[Epoch 153/100000] [Batch 0/2] [D loss: -43.577427] [G loss: -0.201324]\n",
      "[Epoch 154/100000] [Batch 0/2] [D loss: -44.523003] [G loss: -0.061721]\n",
      "[Epoch 155/100000] [Batch 0/2] [D loss: -44.659790] [G loss: 0.683773]\n",
      "[Epoch 156/100000] [Batch 0/2] [D loss: -44.154926] [G loss: 2.284193]\n",
      "[Epoch 157/100000] [Batch 0/2] [D loss: -45.477409] [G loss: 2.179896]\n",
      "[Epoch 158/100000] [Batch 0/2] [D loss: -44.693722] [G loss: 2.126531]\n",
      "[Epoch 159/100000] [Batch 0/2] [D loss: -45.987862] [G loss: 3.027056]\n",
      "[Epoch 160/100000] [Batch 0/2] [D loss: -45.788620] [G loss: 3.121433]\n",
      "[Epoch 161/100000] [Batch 0/2] [D loss: -46.109619] [G loss: 3.049603]\n",
      "[Epoch 162/100000] [Batch 0/2] [D loss: -46.304199] [G loss: 3.049424]\n",
      "[Epoch 163/100000] [Batch 0/2] [D loss: -47.593102] [G loss: 2.660646]\n",
      "[Epoch 164/100000] [Batch 0/2] [D loss: -47.578751] [G loss: 2.666003]\n",
      "[Epoch 165/100000] [Batch 0/2] [D loss: -46.894970] [G loss: 2.820127]\n",
      "[Epoch 166/100000] [Batch 0/2] [D loss: -48.119473] [G loss: 1.878654]\n",
      "[Epoch 167/100000] [Batch 0/2] [D loss: -47.472511] [G loss: 2.324392]\n",
      "[Epoch 168/100000] [Batch 0/2] [D loss: -47.751549] [G loss: 3.812206]\n",
      "[Epoch 169/100000] [Batch 0/2] [D loss: -48.161568] [G loss: 3.301496]\n",
      "[Epoch 170/100000] [Batch 0/2] [D loss: -47.896862] [G loss: 4.548416]\n",
      "[Epoch 171/100000] [Batch 0/2] [D loss: -48.874207] [G loss: 4.338166]\n",
      "[Epoch 172/100000] [Batch 0/2] [D loss: -48.476978] [G loss: 2.605585]\n",
      "[Epoch 173/100000] [Batch 0/2] [D loss: -48.727737] [G loss: 3.209673]\n",
      "[Epoch 174/100000] [Batch 0/2] [D loss: -48.855850] [G loss: 3.476329]\n",
      "[Epoch 175/100000] [Batch 0/2] [D loss: -47.737110] [G loss: 3.064105]\n",
      "[Epoch 176/100000] [Batch 0/2] [D loss: -48.475948] [G loss: 3.888677]\n",
      "[Epoch 177/100000] [Batch 0/2] [D loss: -48.521412] [G loss: 6.064486]\n",
      "[Epoch 178/100000] [Batch 0/2] [D loss: -47.777851] [G loss: 5.556065]\n",
      "[Epoch 179/100000] [Batch 0/2] [D loss: -47.974327] [G loss: 4.750632]\n",
      "[Epoch 180/100000] [Batch 0/2] [D loss: -49.747108] [G loss: 4.698153]\n",
      "[Epoch 181/100000] [Batch 0/2] [D loss: -49.428566] [G loss: 3.175091]\n",
      "[Epoch 182/100000] [Batch 0/2] [D loss: -50.542816] [G loss: 2.694556]\n",
      "[Epoch 183/100000] [Batch 0/2] [D loss: -49.218418] [G loss: 2.893713]\n",
      "[Epoch 184/100000] [Batch 0/2] [D loss: -49.679962] [G loss: 3.652362]\n",
      "[Epoch 185/100000] [Batch 0/2] [D loss: -49.556351] [G loss: 3.905203]\n",
      "[Epoch 186/100000] [Batch 0/2] [D loss: -48.795387] [G loss: 2.853327]\n",
      "[Epoch 187/100000] [Batch 0/2] [D loss: -49.705185] [G loss: 5.948702]\n",
      "[Epoch 188/100000] [Batch 0/2] [D loss: -50.844372] [G loss: 5.014482]\n",
      "[Epoch 189/100000] [Batch 0/2] [D loss: -50.940796] [G loss: 5.361274]\n",
      "[Epoch 190/100000] [Batch 0/2] [D loss: -49.423813] [G loss: 4.734482]\n",
      "[Epoch 191/100000] [Batch 0/2] [D loss: -49.314152] [G loss: 2.456262]\n",
      "[Epoch 192/100000] [Batch 0/2] [D loss: -49.920006] [G loss: 3.493739]\n",
      "[Epoch 193/100000] [Batch 0/2] [D loss: -49.726433] [G loss: 3.676201]\n",
      "[Epoch 194/100000] [Batch 0/2] [D loss: -49.453957] [G loss: 4.416956]\n",
      "[Epoch 195/100000] [Batch 0/2] [D loss: -50.792976] [G loss: 3.335817]\n",
      "[Epoch 196/100000] [Batch 0/2] [D loss: -50.814926] [G loss: 4.087525]\n",
      "[Epoch 197/100000] [Batch 0/2] [D loss: -50.384514] [G loss: 5.430037]\n",
      "[Epoch 198/100000] [Batch 0/2] [D loss: -50.046825] [G loss: 2.590959]\n",
      "[Epoch 199/100000] [Batch 0/2] [D loss: -49.788803] [G loss: 3.897652]\n",
      "[Epoch 200/100000] [Batch 0/2] [D loss: -49.861099] [G loss: 3.491038]\n",
      "[Epoch 201/100000] [Batch 0/2] [D loss: -51.220009] [G loss: 4.320500]\n",
      "[Epoch 202/100000] [Batch 0/2] [D loss: -49.947124] [G loss: 4.285670]\n",
      "[Epoch 203/100000] [Batch 0/2] [D loss: -50.740891] [G loss: 3.559835]\n",
      "[Epoch 204/100000] [Batch 0/2] [D loss: -51.000816] [G loss: 2.824745]\n",
      "[Epoch 205/100000] [Batch 0/2] [D loss: -51.216156] [G loss: 3.606131]\n",
      "[Epoch 206/100000] [Batch 0/2] [D loss: -51.109367] [G loss: 2.723674]\n",
      "[Epoch 207/100000] [Batch 0/2] [D loss: -50.812477] [G loss: 1.174712]\n",
      "[Epoch 208/100000] [Batch 0/2] [D loss: -50.141178] [G loss: 4.133393]\n",
      "[Epoch 209/100000] [Batch 0/2] [D loss: -51.392487] [G loss: 3.752054]\n",
      "[Epoch 210/100000] [Batch 0/2] [D loss: -51.016468] [G loss: 1.284620]\n",
      "[Epoch 211/100000] [Batch 0/2] [D loss: -50.729904] [G loss: 1.511304]\n",
      "[Epoch 212/100000] [Batch 0/2] [D loss: -50.880291] [G loss: 0.420300]\n",
      "[Epoch 213/100000] [Batch 0/2] [D loss: -50.836533] [G loss: 2.898598]\n",
      "[Epoch 214/100000] [Batch 0/2] [D loss: -50.397301] [G loss: 3.101865]\n",
      "[Epoch 215/100000] [Batch 0/2] [D loss: -51.194244] [G loss: -1.397317]\n",
      "[Epoch 216/100000] [Batch 0/2] [D loss: -50.765648] [G loss: 0.814078]\n",
      "[Epoch 217/100000] [Batch 0/2] [D loss: -50.504951] [G loss: 4.312036]\n",
      "[Epoch 218/100000] [Batch 0/2] [D loss: -51.064445] [G loss: -0.998554]\n",
      "[Epoch 219/100000] [Batch 0/2] [D loss: -50.699860] [G loss: -2.116918]\n",
      "[Epoch 220/100000] [Batch 0/2] [D loss: -51.934853] [G loss: 1.055827]\n",
      "[Epoch 221/100000] [Batch 0/2] [D loss: -51.375172] [G loss: 1.941164]\n",
      "[Epoch 222/100000] [Batch 0/2] [D loss: -52.497856] [G loss: 4.711028]\n",
      "[Epoch 223/100000] [Batch 0/2] [D loss: -52.073193] [G loss: 0.314237]\n",
      "[Epoch 224/100000] [Batch 0/2] [D loss: -52.055923] [G loss: -2.526574]\n",
      "[Epoch 225/100000] [Batch 0/2] [D loss: -51.663097] [G loss: -2.247836]\n",
      "[Epoch 226/100000] [Batch 0/2] [D loss: -51.929512] [G loss: -2.317489]\n",
      "[Epoch 227/100000] [Batch 0/2] [D loss: -52.150352] [G loss: -0.753757]\n",
      "[Epoch 228/100000] [Batch 0/2] [D loss: -51.845795] [G loss: -0.427384]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 229/100000] [Batch 0/2] [D loss: -52.542660] [G loss: 2.045557]\n",
      "[Epoch 230/100000] [Batch 0/2] [D loss: -52.399261] [G loss: 0.372228]\n",
      "[Epoch 231/100000] [Batch 0/2] [D loss: -51.293312] [G loss: -3.247748]\n",
      "[Epoch 232/100000] [Batch 0/2] [D loss: -49.893314] [G loss: -3.290461]\n",
      "[Epoch 233/100000] [Batch 0/2] [D loss: -50.901875] [G loss: -4.442164]\n",
      "[Epoch 234/100000] [Batch 0/2] [D loss: -50.907547] [G loss: -1.500412]\n",
      "[Epoch 235/100000] [Batch 0/2] [D loss: -51.332047] [G loss: 3.554350]\n",
      "[Epoch 236/100000] [Batch 0/2] [D loss: -50.788456] [G loss: 2.471179]\n",
      "[Epoch 237/100000] [Batch 0/2] [D loss: -50.946434] [G loss: 2.911094]\n",
      "[Epoch 238/100000] [Batch 0/2] [D loss: -49.992863] [G loss: -7.094117]\n",
      "[Epoch 239/100000] [Batch 0/2] [D loss: -51.184181] [G loss: -4.642399]\n",
      "[Epoch 240/100000] [Batch 0/2] [D loss: -50.651909] [G loss: -1.847223]\n",
      "[Epoch 241/100000] [Batch 0/2] [D loss: -52.872269] [G loss: 2.089391]\n",
      "[Epoch 242/100000] [Batch 0/2] [D loss: -49.732590] [G loss: 0.397702]\n",
      "[Epoch 243/100000] [Batch 0/2] [D loss: -49.649330] [G loss: -1.339711]\n",
      "[Epoch 244/100000] [Batch 0/2] [D loss: -50.510033] [G loss: -5.348317]\n",
      "[Epoch 245/100000] [Batch 0/2] [D loss: -50.040516] [G loss: -5.268018]\n",
      "[Epoch 246/100000] [Batch 0/2] [D loss: -51.309097] [G loss: -0.952928]\n",
      "[Epoch 247/100000] [Batch 0/2] [D loss: -51.609989] [G loss: 3.266685]\n",
      "[Epoch 248/100000] [Batch 0/2] [D loss: -49.734695] [G loss: -4.394208]\n",
      "[Epoch 249/100000] [Batch 0/2] [D loss: -49.976021] [G loss: -8.097643]\n",
      "[Epoch 250/100000] [Batch 0/2] [D loss: -51.148243] [G loss: -6.111148]\n",
      "[Epoch 251/100000] [Batch 0/2] [D loss: -50.846867] [G loss: -2.261855]\n",
      "[Epoch 252/100000] [Batch 0/2] [D loss: -50.277328] [G loss: -3.206133]\n",
      "[Epoch 253/100000] [Batch 0/2] [D loss: -48.650963] [G loss: -3.148760]\n",
      "[Epoch 254/100000] [Batch 0/2] [D loss: -48.266640] [G loss: 0.494092]\n",
      "[Epoch 255/100000] [Batch 0/2] [D loss: -49.705349] [G loss: -7.805920]\n",
      "[Epoch 256/100000] [Batch 0/2] [D loss: -49.433441] [G loss: -9.549846]\n",
      "[Epoch 257/100000] [Batch 0/2] [D loss: -49.968296] [G loss: -7.861537]\n",
      "[Epoch 258/100000] [Batch 0/2] [D loss: -49.291542] [G loss: 0.276148]\n",
      "[Epoch 259/100000] [Batch 0/2] [D loss: -47.602867] [G loss: -13.903661]\n",
      "[Epoch 260/100000] [Batch 0/2] [D loss: -49.032993] [G loss: -5.096037]\n",
      "[Epoch 261/100000] [Batch 0/2] [D loss: -46.543594] [G loss: -8.144384]\n",
      "[Epoch 262/100000] [Batch 0/2] [D loss: -47.599167] [G loss: -5.110031]\n",
      "[Epoch 263/100000] [Batch 0/2] [D loss: -49.013851] [G loss: -6.539514]\n",
      "[Epoch 264/100000] [Batch 0/2] [D loss: -48.519241] [G loss: -11.840096]\n",
      "[Epoch 265/100000] [Batch 0/2] [D loss: -48.201645] [G loss: -4.369937]\n",
      "[Epoch 266/100000] [Batch 0/2] [D loss: -49.393177] [G loss: 2.701332]\n",
      "[Epoch 267/100000] [Batch 0/2] [D loss: -49.507607] [G loss: 13.454956]\n",
      "[Epoch 268/100000] [Batch 0/2] [D loss: -49.073883] [G loss: 12.170140]\n",
      "[Epoch 269/100000] [Batch 0/2] [D loss: -52.061714] [G loss: 22.976929]\n",
      "[Epoch 270/100000] [Batch 0/2] [D loss: -51.242020] [G loss: 20.471540]\n",
      "[Epoch 271/100000] [Batch 0/2] [D loss: -52.586605] [G loss: 30.098976]\n",
      "[Epoch 272/100000] [Batch 0/2] [D loss: -50.683605] [G loss: 30.656790]\n",
      "[Epoch 273/100000] [Batch 0/2] [D loss: -52.874447] [G loss: 35.716103]\n",
      "[Epoch 274/100000] [Batch 0/2] [D loss: -51.641544] [G loss: 35.478226]\n",
      "[Epoch 275/100000] [Batch 0/2] [D loss: -50.498695] [G loss: 34.188431]\n",
      "[Epoch 276/100000] [Batch 0/2] [D loss: -50.469292] [G loss: 36.371891]\n",
      "[Epoch 277/100000] [Batch 0/2] [D loss: -48.692463] [G loss: 36.423809]\n",
      "[Epoch 278/100000] [Batch 0/2] [D loss: -48.836964] [G loss: 35.359070]\n",
      "[Epoch 279/100000] [Batch 0/2] [D loss: -47.819839] [G loss: 28.692625]\n",
      "[Epoch 280/100000] [Batch 0/2] [D loss: -48.145298] [G loss: 28.288307]\n",
      "[Epoch 281/100000] [Batch 0/2] [D loss: -45.612675] [G loss: 20.328617]\n",
      "[Epoch 282/100000] [Batch 0/2] [D loss: -50.514282] [G loss: 19.182461]\n",
      "[Epoch 283/100000] [Batch 0/2] [D loss: -49.414288] [G loss: 21.622089]\n",
      "[Epoch 284/100000] [Batch 0/2] [D loss: -47.729462] [G loss: 21.375235]\n",
      "[Epoch 285/100000] [Batch 0/2] [D loss: -49.699936] [G loss: 28.438044]\n",
      "[Epoch 286/100000] [Batch 0/2] [D loss: -50.208996] [G loss: 35.053379]\n",
      "[Epoch 287/100000] [Batch 0/2] [D loss: -49.229931] [G loss: 30.788544]\n",
      "[Epoch 288/100000] [Batch 0/2] [D loss: -46.635956] [G loss: 28.769054]\n",
      "[Epoch 289/100000] [Batch 0/2] [D loss: -48.975815] [G loss: 31.147573]\n",
      "[Epoch 290/100000] [Batch 0/2] [D loss: -52.159264] [G loss: 25.380484]\n",
      "[Epoch 291/100000] [Batch 0/2] [D loss: -51.752319] [G loss: 33.355240]\n",
      "[Epoch 292/100000] [Batch 0/2] [D loss: -53.093689] [G loss: 33.466999]\n",
      "[Epoch 293/100000] [Batch 0/2] [D loss: -55.724121] [G loss: 25.392748]\n",
      "[Epoch 294/100000] [Batch 0/2] [D loss: -50.665382] [G loss: 18.478836]\n",
      "[Epoch 295/100000] [Batch 0/2] [D loss: -52.878067] [G loss: 22.139105]\n",
      "[Epoch 296/100000] [Batch 0/2] [D loss: -54.937645] [G loss: 6.113914]\n",
      "[Epoch 297/100000] [Batch 0/2] [D loss: -49.519295] [G loss: 26.796593]\n",
      "[Epoch 298/100000] [Batch 0/2] [D loss: -50.328819] [G loss: 23.756168]\n",
      "[Epoch 299/100000] [Batch 0/2] [D loss: -46.247871] [G loss: 27.261124]\n",
      "[Epoch 300/100000] [Batch 0/2] [D loss: -49.724709] [G loss: 14.925386]\n",
      "[Epoch 301/100000] [Batch 0/2] [D loss: -49.396091] [G loss: 2.922345]\n",
      "[Epoch 302/100000] [Batch 0/2] [D loss: -49.286903] [G loss: 10.748798]\n",
      "[Epoch 303/100000] [Batch 0/2] [D loss: -47.851738] [G loss: 12.660159]\n",
      "[Epoch 304/100000] [Batch 0/2] [D loss: -48.006729] [G loss: 10.464051]\n",
      "[Epoch 305/100000] [Batch 0/2] [D loss: -48.955051] [G loss: 1.316972]\n",
      "[Epoch 306/100000] [Batch 0/2] [D loss: -48.010963] [G loss: 1.379483]\n",
      "[Epoch 307/100000] [Batch 0/2] [D loss: -47.383503] [G loss: 8.641582]\n",
      "[Epoch 308/100000] [Batch 0/2] [D loss: -46.491631] [G loss: 18.016708]\n",
      "[Epoch 309/100000] [Batch 0/2] [D loss: -44.206894] [G loss: 7.957363]\n",
      "[Epoch 310/100000] [Batch 0/2] [D loss: -45.375023] [G loss: 6.465729]\n",
      "[Epoch 311/100000] [Batch 0/2] [D loss: -43.751488] [G loss: 8.862620]\n",
      "[Epoch 312/100000] [Batch 0/2] [D loss: -46.569889] [G loss: 19.316267]\n",
      "[Epoch 313/100000] [Batch 0/2] [D loss: -47.052887] [G loss: 13.518816]\n",
      "[Epoch 314/100000] [Batch 0/2] [D loss: -43.258049] [G loss: 24.374371]\n",
      "[Epoch 315/100000] [Batch 0/2] [D loss: -46.834381] [G loss: 30.133446]\n",
      "[Epoch 316/100000] [Batch 0/2] [D loss: -45.853493] [G loss: 18.642160]\n",
      "[Epoch 317/100000] [Batch 0/2] [D loss: -44.986813] [G loss: 23.276876]\n",
      "[Epoch 318/100000] [Batch 0/2] [D loss: -48.814636] [G loss: 21.562738]\n",
      "[Epoch 319/100000] [Batch 0/2] [D loss: -47.694733] [G loss: 27.329262]\n",
      "[Epoch 320/100000] [Batch 0/2] [D loss: -47.327747] [G loss: 20.576805]\n",
      "[Epoch 321/100000] [Batch 0/2] [D loss: -43.958725] [G loss: 14.477983]\n",
      "[Epoch 322/100000] [Batch 0/2] [D loss: -42.973000] [G loss: 8.721284]\n",
      "[Epoch 323/100000] [Batch 0/2] [D loss: -43.519310] [G loss: 15.947694]\n",
      "[Epoch 324/100000] [Batch 0/2] [D loss: -40.615753] [G loss: 15.316849]\n",
      "[Epoch 325/100000] [Batch 0/2] [D loss: -43.323647] [G loss: 19.578781]\n",
      "[Epoch 326/100000] [Batch 0/2] [D loss: -43.504799] [G loss: 20.936344]\n",
      "[Epoch 327/100000] [Batch 0/2] [D loss: -41.038731] [G loss: 14.388830]\n",
      "[Epoch 328/100000] [Batch 0/2] [D loss: -43.374550] [G loss: 11.817566]\n",
      "[Epoch 329/100000] [Batch 0/2] [D loss: -44.156525] [G loss: 17.702679]\n",
      "[Epoch 330/100000] [Batch 0/2] [D loss: -42.860241] [G loss: 19.771189]\n",
      "[Epoch 331/100000] [Batch 0/2] [D loss: -43.626564] [G loss: 7.442417]\n",
      "[Epoch 332/100000] [Batch 0/2] [D loss: -44.151131] [G loss: 12.461498]\n",
      "[Epoch 333/100000] [Batch 0/2] [D loss: -44.596451] [G loss: 15.567900]\n",
      "[Epoch 334/100000] [Batch 0/2] [D loss: -43.553932] [G loss: 10.012196]\n",
      "[Epoch 335/100000] [Batch 0/2] [D loss: -42.130505] [G loss: 14.432994]\n",
      "[Epoch 336/100000] [Batch 0/2] [D loss: -42.317383] [G loss: 6.114941]\n",
      "[Epoch 337/100000] [Batch 0/2] [D loss: -36.894672] [G loss: 14.760868]\n",
      "[Epoch 338/100000] [Batch 0/2] [D loss: -41.200409] [G loss: 25.125675]\n",
      "[Epoch 339/100000] [Batch 0/2] [D loss: -39.747070] [G loss: 20.615183]\n",
      "[Epoch 340/100000] [Batch 0/2] [D loss: -41.496296] [G loss: 17.024612]\n",
      "[Epoch 341/100000] [Batch 0/2] [D loss: -41.284492] [G loss: 18.863369]\n",
      "[Epoch 342/100000] [Batch 0/2] [D loss: -40.135590] [G loss: 18.302284]\n",
      "[Epoch 343/100000] [Batch 0/2] [D loss: -37.753464] [G loss: 26.374771]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 344/100000] [Batch 0/2] [D loss: -39.336689] [G loss: 23.098650]\n",
      "[Epoch 345/100000] [Batch 0/2] [D loss: -40.404198] [G loss: 5.304155]\n",
      "[Epoch 346/100000] [Batch 0/2] [D loss: -37.569607] [G loss: 9.774017]\n",
      "[Epoch 347/100000] [Batch 0/2] [D loss: -38.218678] [G loss: 13.446342]\n",
      "[Epoch 348/100000] [Batch 0/2] [D loss: -38.439167] [G loss: 17.545738]\n",
      "[Epoch 349/100000] [Batch 0/2] [D loss: -37.383102] [G loss: 14.861037]\n",
      "[Epoch 350/100000] [Batch 0/2] [D loss: -36.732582] [G loss: 13.387033]\n",
      "[Epoch 351/100000] [Batch 0/2] [D loss: -36.063248] [G loss: 11.069348]\n",
      "[Epoch 352/100000] [Batch 0/2] [D loss: -38.564377] [G loss: 14.254780]\n",
      "[Epoch 353/100000] [Batch 0/2] [D loss: -35.230751] [G loss: 9.560684]\n",
      "[Epoch 354/100000] [Batch 0/2] [D loss: -35.680161] [G loss: 21.701660]\n",
      "[Epoch 355/100000] [Batch 0/2] [D loss: -38.102859] [G loss: 20.614315]\n",
      "[Epoch 356/100000] [Batch 0/2] [D loss: -39.238235] [G loss: 21.079554]\n",
      "[Epoch 357/100000] [Batch 0/2] [D loss: -40.373619] [G loss: 23.725136]\n",
      "[Epoch 358/100000] [Batch 0/2] [D loss: -41.154400] [G loss: 21.260391]\n",
      "[Epoch 359/100000] [Batch 0/2] [D loss: -41.996044] [G loss: 14.228174]\n",
      "[Epoch 360/100000] [Batch 0/2] [D loss: -40.903641] [G loss: -5.037091]\n",
      "[Epoch 361/100000] [Batch 0/2] [D loss: -39.672436] [G loss: 12.882308]\n",
      "[Epoch 362/100000] [Batch 0/2] [D loss: -39.246670] [G loss: 23.196333]\n",
      "[Epoch 363/100000] [Batch 0/2] [D loss: -41.483593] [G loss: 24.958542]\n",
      "[Epoch 364/100000] [Batch 0/2] [D loss: -39.652271] [G loss: 7.992659]\n",
      "[Epoch 365/100000] [Batch 0/2] [D loss: -37.459007] [G loss: 9.297464]\n",
      "[Epoch 366/100000] [Batch 0/2] [D loss: -38.843468] [G loss: 14.519382]\n",
      "[Epoch 367/100000] [Batch 0/2] [D loss: -39.143867] [G loss: 13.832838]\n",
      "[Epoch 368/100000] [Batch 0/2] [D loss: -35.424782] [G loss: 24.931398]\n",
      "[Epoch 369/100000] [Batch 0/2] [D loss: -37.550224] [G loss: 32.099800]\n",
      "[Epoch 370/100000] [Batch 0/2] [D loss: -44.915176] [G loss: 32.627422]\n",
      "[Epoch 371/100000] [Batch 0/2] [D loss: -37.826763] [G loss: 28.348246]\n",
      "[Epoch 372/100000] [Batch 0/2] [D loss: -40.736942] [G loss: 27.045179]\n",
      "[Epoch 373/100000] [Batch 0/2] [D loss: -43.217255] [G loss: 27.155605]\n",
      "[Epoch 374/100000] [Batch 0/2] [D loss: -44.716656] [G loss: 24.314390]\n",
      "[Epoch 375/100000] [Batch 0/2] [D loss: -40.106224] [G loss: 25.804445]\n",
      "[Epoch 376/100000] [Batch 0/2] [D loss: -40.975792] [G loss: 36.561295]\n",
      "[Epoch 377/100000] [Batch 0/2] [D loss: -44.956207] [G loss: 40.782990]\n",
      "[Epoch 378/100000] [Batch 0/2] [D loss: -42.067787] [G loss: 35.165825]\n",
      "[Epoch 379/100000] [Batch 0/2] [D loss: -40.753864] [G loss: 29.146395]\n",
      "[Epoch 380/100000] [Batch 0/2] [D loss: -46.669781] [G loss: 31.677000]\n",
      "[Epoch 381/100000] [Batch 0/2] [D loss: -46.136337] [G loss: 26.551998]\n",
      "[Epoch 382/100000] [Batch 0/2] [D loss: -39.808914] [G loss: 27.329197]\n",
      "[Epoch 383/100000] [Batch 0/2] [D loss: -42.214848] [G loss: 33.115730]\n",
      "[Epoch 384/100000] [Batch 0/2] [D loss: -42.710934] [G loss: 39.261375]\n",
      "[Epoch 385/100000] [Batch 0/2] [D loss: -43.687840] [G loss: 35.324326]\n",
      "[Epoch 386/100000] [Batch 0/2] [D loss: -42.391373] [G loss: 32.047623]\n",
      "[Epoch 387/100000] [Batch 0/2] [D loss: -40.889523] [G loss: 28.959597]\n",
      "[Epoch 388/100000] [Batch 0/2] [D loss: -45.734070] [G loss: 33.180328]\n",
      "[Epoch 389/100000] [Batch 0/2] [D loss: -42.268429] [G loss: 29.028027]\n",
      "[Epoch 390/100000] [Batch 0/2] [D loss: -42.426292] [G loss: 29.404594]\n",
      "[Epoch 391/100000] [Batch 0/2] [D loss: -43.673397] [G loss: 33.932301]\n",
      "[Epoch 392/100000] [Batch 0/2] [D loss: -46.545494] [G loss: 33.570099]\n",
      "[Epoch 393/100000] [Batch 0/2] [D loss: -41.412262] [G loss: 33.673042]\n",
      "[Epoch 394/100000] [Batch 0/2] [D loss: -43.869118] [G loss: 33.822224]\n",
      "[Epoch 395/100000] [Batch 0/2] [D loss: -47.036186] [G loss: 29.138498]\n",
      "[Epoch 396/100000] [Batch 0/2] [D loss: -42.324303] [G loss: 21.833277]\n",
      "[Epoch 397/100000] [Batch 0/2] [D loss: -40.746613] [G loss: 27.486521]\n",
      "[Epoch 398/100000] [Batch 0/2] [D loss: -38.837605] [G loss: 33.073452]\n",
      "[Epoch 399/100000] [Batch 0/2] [D loss: -42.966805] [G loss: 34.716297]\n",
      "[Epoch 400/100000] [Batch 0/2] [D loss: -41.114067] [G loss: 28.486877]\n",
      "[Epoch 401/100000] [Batch 0/2] [D loss: -39.154243] [G loss: 29.961754]\n",
      "[Epoch 402/100000] [Batch 0/2] [D loss: -41.325073] [G loss: 30.106497]\n",
      "[Epoch 403/100000] [Batch 0/2] [D loss: -43.206059] [G loss: 32.195278]\n",
      "[Epoch 404/100000] [Batch 0/2] [D loss: -43.275658] [G loss: 33.391403]\n",
      "[Epoch 405/100000] [Batch 0/2] [D loss: -41.802284] [G loss: 32.122158]\n",
      "[Epoch 406/100000] [Batch 0/2] [D loss: -43.761574] [G loss: 33.795444]\n",
      "[Epoch 407/100000] [Batch 0/2] [D loss: -42.501614] [G loss: 30.945435]\n",
      "[Epoch 408/100000] [Batch 0/2] [D loss: -41.298943] [G loss: 29.489876]\n",
      "[Epoch 409/100000] [Batch 0/2] [D loss: -41.163429] [G loss: 29.653954]\n",
      "[Epoch 410/100000] [Batch 0/2] [D loss: -42.751167] [G loss: 29.711819]\n",
      "[Epoch 411/100000] [Batch 0/2] [D loss: -47.246872] [G loss: 32.995525]\n",
      "[Epoch 412/100000] [Batch 0/2] [D loss: -42.067875] [G loss: 31.857073]\n",
      "[Epoch 413/100000] [Batch 0/2] [D loss: -43.705589] [G loss: 35.308441]\n",
      "[Epoch 414/100000] [Batch 0/2] [D loss: -45.396999] [G loss: 37.220295]\n",
      "[Epoch 415/100000] [Batch 0/2] [D loss: -46.107666] [G loss: 36.472122]\n",
      "[Epoch 416/100000] [Batch 0/2] [D loss: -43.497406] [G loss: 33.410336]\n",
      "[Epoch 417/100000] [Batch 0/2] [D loss: -43.444443] [G loss: 32.546013]\n",
      "[Epoch 418/100000] [Batch 0/2] [D loss: -47.661064] [G loss: 34.083942]\n",
      "[Epoch 419/100000] [Batch 0/2] [D loss: -48.227333] [G loss: 31.834890]\n",
      "[Epoch 420/100000] [Batch 0/2] [D loss: -44.180595] [G loss: 31.545362]\n",
      "[Epoch 421/100000] [Batch 0/2] [D loss: -43.031456] [G loss: 36.647522]\n",
      "[Epoch 422/100000] [Batch 0/2] [D loss: -44.324074] [G loss: 39.819931]\n",
      "[Epoch 423/100000] [Batch 0/2] [D loss: -42.233562] [G loss: 37.646935]\n",
      "[Epoch 424/100000] [Batch 0/2] [D loss: -45.967865] [G loss: 39.050514]\n",
      "[Epoch 425/100000] [Batch 0/2] [D loss: -41.384949] [G loss: 31.662586]\n",
      "[Epoch 426/100000] [Batch 0/2] [D loss: -44.099323] [G loss: 38.225197]\n",
      "[Epoch 427/100000] [Batch 0/2] [D loss: -40.648087] [G loss: 33.348663]\n",
      "[Epoch 428/100000] [Batch 0/2] [D loss: -42.877586] [G loss: 35.593998]\n",
      "[Epoch 429/100000] [Batch 0/2] [D loss: -42.456753] [G loss: 34.092602]\n",
      "[Epoch 430/100000] [Batch 0/2] [D loss: -46.587273] [G loss: 38.062469]\n",
      "[Epoch 431/100000] [Batch 0/2] [D loss: -43.545532] [G loss: 31.954044]\n",
      "[Epoch 432/100000] [Batch 0/2] [D loss: -41.133167] [G loss: 32.882328]\n",
      "[Epoch 433/100000] [Batch 0/2] [D loss: -43.871651] [G loss: 31.617935]\n",
      "[Epoch 434/100000] [Batch 0/2] [D loss: -43.398521] [G loss: 32.595261]\n",
      "[Epoch 435/100000] [Batch 0/2] [D loss: -44.881210] [G loss: 33.588718]\n",
      "[Epoch 436/100000] [Batch 0/2] [D loss: -44.728500] [G loss: 33.183853]\n",
      "[Epoch 437/100000] [Batch 0/2] [D loss: -43.868874] [G loss: 33.869980]\n",
      "[Epoch 438/100000] [Batch 0/2] [D loss: -43.824539] [G loss: 33.229080]\n",
      "[Epoch 439/100000] [Batch 0/2] [D loss: -47.017887] [G loss: 35.622692]\n",
      "[Epoch 440/100000] [Batch 0/2] [D loss: -44.334057] [G loss: 35.650295]\n",
      "[Epoch 441/100000] [Batch 0/2] [D loss: -43.449722] [G loss: 37.192009]\n",
      "[Epoch 442/100000] [Batch 0/2] [D loss: -49.794701] [G loss: 39.848354]\n",
      "[Epoch 443/100000] [Batch 0/2] [D loss: -46.364414] [G loss: 35.829342]\n",
      "[Epoch 444/100000] [Batch 0/2] [D loss: -46.267860] [G loss: 36.230843]\n",
      "[Epoch 445/100000] [Batch 0/2] [D loss: -47.617996] [G loss: 35.840572]\n",
      "[Epoch 446/100000] [Batch 0/2] [D loss: -45.989815] [G loss: 34.795460]\n",
      "[Epoch 447/100000] [Batch 0/2] [D loss: -49.997620] [G loss: 38.465202]\n",
      "[Epoch 448/100000] [Batch 0/2] [D loss: -47.626984] [G loss: 37.213406]\n",
      "[Epoch 449/100000] [Batch 0/2] [D loss: -47.194283] [G loss: 37.382374]\n",
      "[Epoch 450/100000] [Batch 0/2] [D loss: -45.591637] [G loss: 38.421925]\n",
      "[Epoch 451/100000] [Batch 0/2] [D loss: -46.367233] [G loss: 35.712471]\n",
      "[Epoch 452/100000] [Batch 0/2] [D loss: -46.733688] [G loss: 37.583828]\n",
      "[Epoch 453/100000] [Batch 0/2] [D loss: -47.833382] [G loss: 36.950943]\n",
      "[Epoch 454/100000] [Batch 0/2] [D loss: -44.318481] [G loss: 34.575275]\n",
      "[Epoch 455/100000] [Batch 0/2] [D loss: -45.090908] [G loss: 38.704582]\n",
      "[Epoch 456/100000] [Batch 0/2] [D loss: -51.309319] [G loss: 39.073711]\n",
      "[Epoch 457/100000] [Batch 0/2] [D loss: -46.154942] [G loss: 37.038986]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 458/100000] [Batch 0/2] [D loss: -45.582809] [G loss: 39.544418]\n",
      "[Epoch 459/100000] [Batch 0/2] [D loss: -45.687492] [G loss: 38.410225]\n",
      "[Epoch 460/100000] [Batch 0/2] [D loss: -44.402382] [G loss: 34.663109]\n",
      "[Epoch 461/100000] [Batch 0/2] [D loss: -45.632690] [G loss: 35.091106]\n",
      "[Epoch 462/100000] [Batch 0/2] [D loss: -43.365822] [G loss: 35.230347]\n",
      "[Epoch 463/100000] [Batch 0/2] [D loss: -45.645363] [G loss: 37.894215]\n",
      "[Epoch 464/100000] [Batch 0/2] [D loss: -47.332092] [G loss: 42.787342]\n",
      "[Epoch 465/100000] [Batch 0/2] [D loss: -49.251446] [G loss: 43.610321]\n",
      "[Epoch 466/100000] [Batch 0/2] [D loss: -47.503105] [G loss: 42.020851]\n",
      "[Epoch 467/100000] [Batch 0/2] [D loss: -44.207432] [G loss: 39.894974]\n",
      "[Epoch 468/100000] [Batch 0/2] [D loss: -48.364635] [G loss: 40.712986]\n",
      "[Epoch 469/100000] [Batch 0/2] [D loss: -45.636623] [G loss: 36.952148]\n",
      "[Epoch 470/100000] [Batch 0/2] [D loss: -43.384735] [G loss: 37.237061]\n",
      "[Epoch 471/100000] [Batch 0/2] [D loss: -44.190067] [G loss: 38.005714]\n",
      "[Epoch 472/100000] [Batch 0/2] [D loss: -45.542656] [G loss: 41.846291]\n",
      "[Epoch 473/100000] [Batch 0/2] [D loss: -46.360985] [G loss: 42.521866]\n",
      "[Epoch 474/100000] [Batch 0/2] [D loss: -49.169205] [G loss: 45.571983]\n",
      "[Epoch 475/100000] [Batch 0/2] [D loss: -50.048714] [G loss: 44.972229]\n",
      "[Epoch 476/100000] [Batch 0/2] [D loss: -44.831421] [G loss: 41.749367]\n",
      "[Epoch 477/100000] [Batch 0/2] [D loss: -48.316212] [G loss: 41.953403]\n",
      "[Epoch 478/100000] [Batch 0/2] [D loss: -45.498810] [G loss: 38.228695]\n",
      "[Epoch 479/100000] [Batch 0/2] [D loss: -47.630005] [G loss: 38.717361]\n",
      "[Epoch 480/100000] [Batch 0/2] [D loss: -46.084061] [G loss: 40.786674]\n",
      "[Epoch 481/100000] [Batch 0/2] [D loss: -46.902534] [G loss: 40.945618]\n",
      "[Epoch 482/100000] [Batch 0/2] [D loss: -47.233311] [G loss: 42.227966]\n",
      "[Epoch 483/100000] [Batch 0/2] [D loss: -46.797512] [G loss: 39.689388]\n",
      "[Epoch 484/100000] [Batch 0/2] [D loss: -49.773804] [G loss: 40.357899]\n",
      "[Epoch 485/100000] [Batch 0/2] [D loss: -45.345352] [G loss: 37.119019]\n",
      "[Epoch 486/100000] [Batch 0/2] [D loss: -45.042938] [G loss: 38.422462]\n",
      "[Epoch 487/100000] [Batch 0/2] [D loss: -46.823032] [G loss: 40.138542]\n",
      "[Epoch 488/100000] [Batch 0/2] [D loss: -47.205269] [G loss: 41.361629]\n",
      "[Epoch 489/100000] [Batch 0/2] [D loss: -46.923275] [G loss: 41.230782]\n",
      "[Epoch 490/100000] [Batch 0/2] [D loss: -48.271484] [G loss: 40.395767]\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"train_layout.py\", line 228, in <module>\n",
      "    train_wgan()\n",
      "  File \"train_layout.py\", line 158, in train_wgan\n",
      "    for i, (imgs, xs) in enumerate(dataloader):\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 560, in __next__\n",
      "    batch = self.collate_fn([self.dataset[i] for i in indices])\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 560, in <listcomp>\n",
      "    batch = self.collate_fn([self.dataset[i] for i in indices])\n",
      "  File \"/notebooks/CoordConv-pytorch/experiments/gan/munit/datasets.py\", line 46, in __getitem__\n",
      "    im = Image.open(self.files[index % len(self.files)])\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/PIL/Image.py\", line 2661, in open\n",
      "    prefix = fp.read(16)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "%cd /notebooks/CoordConv-pytorch/experiments/gan/munit/\n",
    "!rm -R images\n",
    "!python train_layout.py --latent_dim=4 --channels=1 --img_size=64 --n_epochs=100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "18//4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
